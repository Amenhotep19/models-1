{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection: R-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from object_detection.utils.visualization_utils import visualize_boxes_and_labels_on_image_array\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_URL = 'http://localhost:8501/v1/models/rfcn:predict'\n",
    "IMAGES_PATH = '/home/<user>/coco/val/val2017' # Edit this to your COCO validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image(image_dir):\n",
    "    image_path = os.path.join(image_dir, random.choice(os.listdir(image_dir)))\n",
    "    image = Image.open(image_path)\n",
    "    (im_width, im_height) = image.size\n",
    "    \n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def visualize(output_dict, image_np):\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'])\n",
    "    output_dict['detection_classes'] = np.array(output_dict['detection_classes']).astype(np.uint8)\n",
    "    output_dict['detection_boxes'] = np.array(output_dict['detection_boxes'])\n",
    "    output_dict['detection_scores'] = np.array(output_dict['detection_scores'])\n",
    "\n",
    "    # Visualize the results of a detection\n",
    "    visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        {1: {'id': 1, 'name': 'object'}}, # Empty category index\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure()\n",
    "    plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image = get_random_image(IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_request = '{\"instances\" : %s}' % np.expand_dims(np_image, 0).tolist()\n",
    "result = requests.post(SERVER_URL, data=predict_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(result.json()['predictions'][0], np_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(batch_size=1, num_iteration=40, warm_up_iteration=10):\n",
    "    i = 0\n",
    "    total_time = 0\n",
    "    for _ in range(num_iteration):\n",
    "        i += 1\n",
    "        np_images = np.repeat(np.expand_dims(get_random_image(IMAGES_PATH), 0).tolist(), batch_size, axis=0).tolist()\n",
    "        predict_request = '{\"instances\" : %s}' % np_images\n",
    "        start_time = time.time()\n",
    "        requests.post(SERVER_URL, data=predict_request)\n",
    "        time_consume = time.time() - start_time\n",
    "        print('Iteration %d: %.3f sec' % (i, time_consume))\n",
    "        if i > warm_up_iteration:\n",
    "            total_time += time_consume\n",
    "\n",
    "    time_average = total_time / (num_iteration - warm_up_iteration)\n",
    "    print('Average time: %.3f sec' % (time_average))\n",
    "    print('Batch size = %d' % batch_size)\n",
    "    if batch_size == 1:\n",
    "        print('Latency: %.3f ms' % (time_average * 1000))\n",
    "    print('Throughput: %.3f images/sec' % (batch_size / time_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time Inference (latency, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
